defaults:
  - _self_


text_model_name: "huawei-noah/TinyBERT_General_4L_312D"
model:
  _target_: pipeline.DiffusionModel
  diffusion_model:
    _target_: model.DiffusionModel
  text_model:
    _target_: transformers.AutoModel.from_pretrained
    pretrained_model_name_or_path: ${text_model_name}
  tokenizer:
    _target_: transformers.AutoTokenizer.from_pretrained
    pretrained_model_name_or_path: ${text_model_name}
  sampler: 
    _target_: samplers.EulerSampler
    beta_start: 0.0001
    beta_end: 0.02
    num_train_timesteps: 1000
    beta_schedule: "linear"
  criterion:
    _target_: torch.nn.MSELoss
    reduction: mean
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    weight_decay: 0.03
  scheduler:
    _target_: util.LRCosineScheduler
    _partial_: true
    warmup_steps: 1078
    cycle_steps: 6471
    cycle_mult: 1
    max_lr: 0.003
    min_lr: 0.000002
    gamma: 1.0
  train_metrics:
    _target_: torch.nn.ModuleDict
    modules:
      mse:
        _target_: torchmetrics.MeanAbsoluteError
      mae:
        _target_: torchmetrics.MeanSquaredError
        squared: false

train_loader:
  _target_: torch.utils.data.DataLoader
  dataset:
    _target_: data.DiffDataset
    caption_path: "/kaggle/input/coco-64-diffusion/coco_64/coco.csv"
    img_dir: "/kaggle/input/coco-64-diffusion/coco_64/"
    tokenizer:
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${text_model_name}
    max_length: 64
    transforms:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.ToTensor
        - _target_: torchvision.transforms.Normalize
          mean: [0.5, 0.5, 0.5]
          std: [0.5, 0.5, 0.5]
  batch_size: 96
  shuffle: True
  num_workers: 4
  pin_memory: True

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: "."
    filename: "epoch_{epoch:02d}-{train_loss:.3f}"
    monitor: "train_loss"
    mode: "min"
    save_top_k: 1
    every_n_train_steps: 200
    auto_insert_metric_name: True
    save_weights_only: False

  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step

  - _target_: lightning.pytorch.callbacks.TQDMProgressBar
    leave: false
    refresh_rate: 20

logger:
  _target_: lightning.pytorch.loggers.wandb.WandbLogger
  save_dir: "."
  project: "Diffusion Model"

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  min_epochs: 1
  max_epochs: 3
  accelerator: gpu
  devices: 2
  strategy: ddp_find_unused_parameters_true
  precision: 16
  gradient_clip_algorithm: "norm"
  gradient_clip_val: 1.0
  log_every_n_steps: 1
  enable_model_summary: False
  deterministic: False
  callbacks: ${callbacks}
  logger: ${logger}

